---
layout: post
tags: []
title: "Captcha"
date: 2019-09-04 03:51:44 +0000
excerpt: "Eu não gosto do Disqus (embora eu uso ele por ser prático). Seria bom eu tirar ele e colocar outro sistema de comentários, como o..."
---

Eu não gosto do Disqus (embora eu uso ele por ser prático). Seria bom eu tirar ele e colocar outro sistema de comentários, como o [Staticman](https://staticman.net/). Acho interessante se eu conseguisse fazer uma implementação dele usando algum servidor gratuito como o Netlify, Now ou Firebase. Encontrei [um tutorial mostrando](https://bloggerbust.ca/post/staticman-with-github-and-zeit-now-part-2/) como fazer isso, então sei que é possível (mas acho que consigo fazer melhor do que isso).

![inline image](https://res.cloudinary.com/qgustavor/image/upload/v1567569098/ctjzmq082p9kzidajdah.png){: .side-image}

Dessa forma eu poderia ajustar o funcionamento do captcha. Por exemplo, começasse a aparecer muito spam eu poderia testar ele para treinar o sistema de conversão de animes mal traduzidos para animes menos mal traduzidos:

![inline image](https://i.imgur.com/2ftSczv.png)

A ideia desse projeto era eu criar uma ferramenta que conseguisse converter animes hardsub em animes softsub com o mínimo de trabalho possível. Sei que existem ferramentas que fazem isso, mas a maioria delas - talvez todas elas - têm uma taxa de erros tão alta que os resultados precisam de uma revisão manual árdua.

Obviamente eu me inspirei no reCAPTCHA antigo, aquele que mostrava duas palavras sendo que às vezes uma delas era apenas para controle e a segunda era uma que não tinha sido reconhecida pelo OCR que eles usavam. Dessa forma, com a interação humana, foi possível otimizar o OCR deles para lidar com casos que na época eram complexos, como textos ilegíveis e fontes estranhas.

Seguindo a mesma linha de raciocínio esse captcha às vezes mostraria uma imagem de controle e outra que o OCR não conseguiu ler. Já testei ele em um site e não ouvi muitas reclamações.

Não foi algo tão fácil de implementar: no princípio ele nem conseguia dividir as palavras de cada frase individualmente e portanto mostrava a frase inteira:

![inline image](https://i.imgur.com/juw8z6b.png)

Trabalhei nesse projeto por anos: fui aprendendo a trabalhar com diversas tecnologias usando essas imagens. Tentei usar redes neurais: treinei algumas redes por horas - talvez dias - mas não consegui resultados bons. Finalmente tentei usar o OpenCV para tentar detectar os limites entre as palavras, com ótimos resultados:

![inline image](https://i.imgur.com/bfgfCsl.png)

Mesmo assim nem não foi fácil chegar nesse ponto e nem sempre ele consegue se sair tão bem: o script tem problemas com imagens com pouco contraste, ruído, letras finas, fontes pequenas, vírgulas e pontos. Nessa imagem a cor do texto é muito similar com a cor do fundo:

![inline image](https://res.cloudinary.com/qgustavor/image/upload/v1567569102/asbm7ifjofltgk215xyb.png)

Nessa imagem a fonte é tão fina que o script ignora algumas letras:

![inline image](https://i.imgur.com/x1n5U6a.png)

Em alguns casos a qualidade do vídeo é baixa e o script não consegue unir as partes da imagem e identificar o texto:

![inline image](https://i.imgur.com/AbYBrCy.png)

Para esse caso e os anteriores criei uma interface para verificar como está o desempenho do script e - como no caso da imagem anterior - corrigir os resultados manualmente.

No fim das contas percebi algo: por mais que ferramentas especializadas em converter vídeos hardsub para softsub tenham problemas para ler isso, por outro lado, até o Google Translate consegue ler isso. Com mais alguns ajustes daria para melhorar o sistema ao ponto de não precisar de mais ajustes manuais e talvez nem precisaria mais de um captcha. Caso eu ainda quisesse o captcha então para melhorar a segurança eu poderia distorcer a imagem para atrapalhar, que nem o reCAPTCHA antigo. Da mesma forma, eu poderia aplicar essas técnicas para reduzir a quantidade de imagens que são legíveis para OCRs e focar em imagens mais difíceis.

Mas então notei algo que faria eu desistir de vez desse projeto: nenhuma ferramenta iria conseguir converter animes mal traduzidos em animes bem traduzidos: boa parte dos animes que peguei para converter para softsub tinham inúmeros erros. Isso faz sentido se considerarmos que é extremamente difícil corrigir erros quando um grupo usa hardsub: se o grupo perdeu os arquivos originais (o que é comum) ou se o grupo não existe mais (o que também é comum) se o grupo se recusa a corrigir (o que é mais comum ainda) a única opção que sobra é ter que fazer a legenda de novo… ou fingir que o erro não existe.

Essa última opção é hipocrisia para os que dizem se preocupar com qualidade. Se alguém se preocupa com qualidade fingir que um erro não existe é ir contra os próprios princípios. Se um erro foi encontrado então que ele seja corrigido. A tradução de um vídeo não é como uma construção onde um erro para ser corrigido envolve muito dinheiro.

Por tanto mesmo se eu fizesse uma ferramenta consiga ler os textos com exatidão por outro lado é extremamente complicado fazer uma que detecte erros de tradução. Se alguém acha que não é difícil dê uma olhada no bug tracker do LanguageTool… fui comentar uma coisa um dia lá e o pessoal saiu justificando que não é possível fazer uma ferramenta perfeita, sempre haverão falsos positivos e falsos negativos. Eu acho que é possível otimizar, com tecnologias novas, redes neurais talvez, mas isso está fora da minha capacidade.

Por tanto desisti deste projeto. O código ainda funciona, então talvez um dia eu o use em algum site meu… como no sistema de comentários daqui.